{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c880625c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notebook to evaluate BASF's prediction script.\n",
    "#Import statements\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from typing import Any, List, Optional, Tuple\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "#from ase import io\n",
    "from ase.atoms import Atoms\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "from conf_solv.trainer import LitConfSolvModule\n",
    "from conf_solv.dataloaders.loader import create_pairdata\n",
    "from conf_solv.dataloaders.features import MolGraph\n",
    "from conf_solv.model.model import ConfSolv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44990a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf153695",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the xyz file.\n",
    "def read_xyz(fileobj):\n",
    "    # This function reads first all atoms and then yields based on the index.\n",
    "    # Perfomance could be improved, but this serves as a simple reference.\n",
    "    # It'd require more code to estimate the total number of images\n",
    "    # without reading through the whole file (note: the number of atoms\n",
    "    # can differ for every image).\n",
    "    lines = fileobj.readlines()\n",
    "    images = []\n",
    "    name_options = [\"name\", \"id\"]\n",
    "    i = 0\n",
    "    while len(lines) > 0:\n",
    "        symbols = []\n",
    "        positions = []\n",
    "        natoms = int(lines.pop(0))\n",
    "        comment_line = lines.pop(0).strip()  # Comment line; ignored\n",
    "        comment_line_split = comment_line.split(' ')\n",
    "        comment = None\n",
    "        for item in comment_line_split:\n",
    "            for name in name_options:\n",
    "                if item.startswith(f\"{name}=\"):\n",
    "                    comment = item.replace(f\"{name}=\", \"\")\n",
    "                    break\n",
    "            if comment:\n",
    "                break\n",
    "        if not comment:\n",
    "            comment = str(i)\n",
    "        for _ in range(natoms):\n",
    "            line = lines.pop(0)\n",
    "            symbol, x, y, z = line.split()[:4]\n",
    "            symbol = symbol.lower().capitalize()\n",
    "            symbols.append(symbol)\n",
    "            positions.append([float(x), float(y), float(z)])\n",
    "        images.append((Atoms(symbols=symbols, positions=positions), comment))\n",
    "        i += 1\n",
    "    for atoms in images[:]:\n",
    "        yield atoms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccd88630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_solute_mols(solute_mols, n_anchor_mols=10, n_threshold_mols=50):\n",
    "    anchor_mols = solute_mols[:n_anchor_mols]\n",
    "    other_mols = solute_mols[n_anchor_mols:]\n",
    "    n_chunks = int(np.ceil(len(other_mols) / (n_threshold_mols - n_anchor_mols)))\n",
    "    batch_ids = [(i*(n_threshold_mols - n_anchor_mols), (i+1)*(n_threshold_mols - n_anchor_mols)) for i in range(n_chunks)]\n",
    "    batch_solute_mols = [anchor_mols + other_mols[a:b] for (a,b) in batch_ids]\n",
    "    return batch_solute_mols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38a4df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ase_atoms_from_xyz(xyz_path):\n",
    "    #ase_atoms_from_xyz = io.read(xyz_path, index=':')\n",
    "    with open(xyz_path, 'r') as f:\n",
    "        ase_atoms_from_xyz = list(read_xyz(f))\n",
    "    return ase_atoms_from_xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f8ca8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(xss):\n",
    "    return [x for xs in xss for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7876c2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lightning_model(trained_model_dir,i):\n",
    "    models = [LitConfSolvModule.load_from_checkpoint(os.path.join(trained_model_dir, f'ensemble_{i}','best_model.ckpt'))]\n",
    "    return models\n",
    "\n",
    "def load_lightning_model_parallel(trained_model_dir,ensemble_nos):\n",
    "    models = Parallel(n_jobs=len(ensemble_nos))([delayed(load_lightning_model)(trained_model_dir,i) for i in ensemble_nos])\n",
    "    models = flatten(models)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3290aa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfsolvPrediction:\n",
    "    \n",
    "    def __init__(self, n_threshold_mols: int = 50, n_anchor_mols: int = 0, num_cores: int = -1, silent=False) -> None:\n",
    "        self.n_threshold_mols: int = n_threshold_mols\n",
    "        self.n_anchor_mols: int = n_anchor_mols\n",
    "        self.models: Optional[List[ConfSolv]] = None\n",
    "        self.model_parameters: Optional[Any] = None\n",
    "        self.solute_mols: Optional[List[Atoms]] = None\n",
    "        self.solute_names: Optional[List[str]] = None\n",
    "        self.solvent_df: Optional[pd.DataFrame] = None\n",
    "        self.trained_model_dir = None\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        #self.device = 'cpu'\n",
    "        print(f'Device being used is {self.device}')\n",
    "        self.silent = silent\n",
    "        print(f'Number of cores requested is {num_cores}')\n",
    "        if num_cores != -1:\n",
    "            torch.set_num_threads(num_cores)\n",
    "        threads = torch.get_num_threads()\n",
    "        print(f'Number of threads used by torch is {threads}')\n",
    "        \n",
    "        \n",
    "    def load_models(self, trained_model_dir: str = 'confsolv_models/nonionic_solvents_scaffold') -> None:\n",
    "        \"\"\"\n",
    "        Load pretrained models.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        trained_model_dir : str, optional\n",
    "            path to the trained model, by default 'confsolv_models/nonionic_solvents_scaffold'\n",
    "            use 'confsolv_models/ionic_solvents_scaffold' for ionic solvents\n",
    "        \"\"\"\n",
    "        self.trained_model_dir = Path(trained_model_dir)\n",
    "        ensemble_nos = len([x for x in self.trained_model_dir.iterdir() if x.is_dir()])\n",
    "        print(f\"Loading model {self.trained_model_dir.name} with {ensemble_nos} ensembles...\")\n",
    "        self.models = load_lightning_model_parallel(trained_model_dir, range(ensemble_nos))\n",
    "        \n",
    "    def load_solutes(self, xyz_file: str) -> None:\n",
    "        \"\"\"\n",
    "        Load solutes from xyz file.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        xyz_file : str\n",
    "            path to the xyz file containing all molecules to be evaluated\n",
    "\n",
    "        \"\"\"\n",
    "        solute_mols_and_names = ase_atoms_from_xyz(xyz_file)\n",
    "        self.solute_mols = [item[0] for item in solute_mols_and_names]\n",
    "        self.solute_names = [item[1] for item in solute_mols_and_names]\n",
    "\n",
    "    def load_solvents(self, solvent_file: str) -> None:\n",
    "        \"\"\"\n",
    "        Load solvents as pandas dataframe from csv file. Headers must be SOLVENT_NAME and SMILES.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        solvent_file : str\n",
    "            path to solvent csv file (Headers must be SOLVENT_NAME and SMILES).\n",
    "        \"\"\"\n",
    "        solvent_df = pd.read_csv(solvent_file)\n",
    "        if \"SOLVENT_NAME\" not in solvent_df.columns or \"SMILES\" not in solvent_df.columns:\n",
    "            raise Exception(\"Solvent file does not have necessary columns (SOLVENT_NAME, SMILES).\")\n",
    "        self.solvent_df = solvent_df[['SOLVENT_NAME', 'SMILES']]\n",
    "\n",
    "    def predict_all_solutes_all_solvents(self) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        print(\"Running prediction...\")\n",
    "        result_df = pd.DataFrame()\n",
    "        std_df = pd.DataFrame()\n",
    "        conf_name_col = 'CONF_NAME'\n",
    "        if self.n_anchor_mols == 0:\n",
    "            result_df[conf_name_col] = self.solute_names\n",
    "            std_df[conf_name_col] = self.solute_names\n",
    "        solvent_data_iterator = self.solvent_df.index if self.silent else tqdm(self.solvent_df.index)\n",
    "        for index in solvent_data_iterator:  \n",
    "            solvent_smi = self.solvent_df.at[index, 'SMILES']\n",
    "            solvent_name = self.solvent_df.at[index, 'SOLVENT_NAME']\n",
    "            preds, stds = self._predict_all_solutes_single_solvent(solvent_smi=solvent_smi)\n",
    "            result_df[solvent_name] = preds\n",
    "            std_df[solvent_name] = stds\n",
    "        print(\"Prediction completed.\")\n",
    "        return result_df, std_df\n",
    "\n",
    "    def _predict_all_solutes_single_solvent(self, solvent_smi: str) -> Tuple[np.array, np.array]:\n",
    "        # change solvent_smi for predictions in a different solvent\n",
    "        solvent_molgraph = MolGraph(solvent_smi)\n",
    "        # batch solute mols\n",
    "        # split input into [n_anchor_mols + (n_threshold_mols-n_anchor_mols)] sections\n",
    "        # should only trigger when n_solute_mols > n_threshold_mols\n",
    "        # ideally, n_threshold_mols is as large as possible\n",
    "        if len(self.solute_mols) > self.n_threshold_mols:\n",
    "            batch_solute_mols = divide_solute_mols(self.solute_mols,\n",
    "                                                n_anchor_mols=self.n_anchor_mols,\n",
    "                                                n_threshold_mols=self.n_threshold_mols)\n",
    "        else:\n",
    "            batch_solute_mols = [self.solute_mols]\n",
    "        n_atoms = batch_solute_mols[0][0].get_global_number_of_atoms()\n",
    "\n",
    "        #out_final = torch.tensor([])\n",
    "        out_final = torch.empty(0)\n",
    "        for batch_idx, solute_mols in enumerate(batch_solute_mols):\n",
    "            data = create_pairdata(solvent_molgraph, solute_mols, len(solute_mols))\n",
    "            data.solute_confs_batch = torch.concat([torch.zeros([n_atoms],dtype=torch.int64) + i for i in range( len(solute_mols))])\n",
    "            batch_data = Batch.from_data_list([data], follow_batch=['x_solvent', 'x_solute'])\n",
    "            if self.device == 'cuda':\n",
    "                #batch_data.to(self.device)\n",
    "                batch_data.cuda()\n",
    "                for model in self.models:\n",
    "                    model.cuda()\n",
    "                    #model.to(self.device)\n",
    "            with torch.no_grad():\n",
    "                for model in self.models:\n",
    "                    model.eval()\n",
    "                    print(f\"Envelope_a {model.model.solute_model.rbf.envelope.a}\")\n",
    "                    print(f\"Envelope_b {model.model.solute_model.rbf.envelope.b}\")\n",
    "                    print(f\"Envelope_c {model.model.solute_model.rbf.envelope.c}\")\n",
    "                    print(f\"Envelope_p {model.model.solute_model.rbf.envelope.p}\")\n",
    "                out = torch.stack([model(batch_data,len(solute_mols)) for model in self.models])\n",
    "            out = out.cpu()\n",
    "            out_final = torch.cat([out_final, out], dim=-1)\n",
    "        out_scaled = out_final - out_final.min(dim=1, keepdim=True).values #Scale each prediction relative to lowest energy conformer.\\n\",\n",
    "        stds = out_scaled.std(dim=0)\n",
    "        preds = out_scaled.mean(dim=0)\n",
    "        preds = preds - preds.min()\n",
    "        return preds.cpu().numpy(), stds.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8db83f6-5db9-4e90-bd3c-507b2453e414",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f1366ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll define an inference function to help us.\n",
    "def inference(xyz_file, solvent_file, out_path, out_path_uncertainty, n_threshold_mols=1000, n_anchor_mols=0, num_cores=-1, silent=False):\n",
    "    model_path = f'../sample_trained_models/'\n",
    "    prediction = ConfsolvPrediction(n_threshold_mols=n_threshold_mols, n_anchor_mols=n_anchor_mols, num_cores=num_cores, silent=silent)\n",
    "    \n",
    "    START = time.time()\n",
    "    prediction.load_models(model_path)\n",
    "    print(f'Elapsed time for task load models is {time.time() - START:.2f} seconds')\n",
    "    \n",
    "    START = time.time()\n",
    "    prediction.load_solutes(xyz_file)\n",
    "    print(f'Elapsed time for task load conformers is {time.time() - START:.2f} seconds')\n",
    "    \n",
    "    START = time.time()\n",
    "    prediction.load_solvents(solvent_file)\n",
    "    print(f'Elapsed time for task load solvents is {time.time() - START:.2f} seconds')\n",
    "    \n",
    "    START = time.time()\n",
    "    result_df, std_df = prediction.predict_all_solutes_all_solvents()\n",
    "    print(f'Elapsed time for task make predictions is {time.time() - START:.2f} seconds')\n",
    "    \n",
    "    result_df.to_csv(out_path)\n",
    "    std_df.to_csv(out_path_uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdc6de16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data1/groups/RMG/Projects/BASF/conf_solv/BASF_predict'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get current directory -> for path and variable initialization\n",
    "maindir = os.getcwd()\n",
    "maindir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ee27673",
   "metadata": {},
   "outputs": [],
   "source": [
    "xyzfile = os.path.join(maindir,'example.xyz')\n",
    "solventfile = os.path.join(maindir, 'solvents_example.act')\n",
    "outfile = os.path.join(maindir, 'outpreds.csv')\n",
    "uncertfile = os.path.join(maindir, 'outstd.csv')\n",
    "thresholdmols = 100 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81068d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run inference\n",
    "seed_everything(seed=10608)\n",
    "inference(xyzfile, solventfile, outfile, uncertfile, thresholdmols, num_cores = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d761a2b-0e38-4e5d-a398-3ce28d6e06d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af478fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-ConfSolv]",
   "language": "python",
   "name": "conda-env-.conda-ConfSolv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
